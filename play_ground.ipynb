{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "from models import DGNN, AAGNN, EGNNC\n",
    "from models_variants import EAAGNN, EAACGNN\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "--------------------------------\n",
      "Reading edge dataset from Val\\P28_10_5\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "self.features.shape: torch.Size([1852, 4])\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "self.mode != 'train'\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: val\n",
      "Number of vertices: 1852\n",
      "Number of edges: 5514\n",
      "Number of triangles: 3671\n",
      "Number of positive/negative datapoints: 412/5102\n",
      "Number of examples/datapoints: 5514\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set up arguments for datasets, models and training.\n",
    "is_train = True\n",
    "is_test = False\n",
    "is_val = True\n",
    "is_debug = False\n",
    "conf_device = None\n",
    "hidden_dim = [8]\n",
    "batch_size = 32\n",
    "dataset_folder = \"ground_truth\"\n",
    "\n",
    "num_layers = len(hidden_dim) + 1\n",
    "\n",
    "\n",
    "if False and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "conf_device = device\n",
    "\n",
    "# Get the dataset, dataloader and model.\n",
    "if not is_val and not is_test:\n",
    "    dataset_args = ('train', num_layers)\n",
    "\n",
    "if is_val:\n",
    "    dataset_args = ('val', num_layers)\n",
    "\n",
    "if is_test:\n",
    "    dataset_args = ('test', num_layers)\n",
    "\n",
    "datasets = utils.get_dataset_gcn(dataset_args, dataset_folder, is_debug=is_debug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "loaders = []\n",
    "for i in range(len(datasets)):\n",
    "    loaders.append(DataLoader(dataset=datasets[i], batch_size=batch_size,\n",
    "                    shuffle=True, collate_fn=datasets[i].collate_wrapper))\n",
    "                    \n",
    "loader = DataLoader(dataset=datasets[0], batch_size=batch_size,\n",
    "                    shuffle=False, collate_fn=datasets[0].collate_wrapper)\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    adj, features, edge_features, adj_relative_cos, edges, labels, dist = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriangularMotifsCNN(nn.Module):\n",
    "    def __init__(self, num_channels = 4, output_dim = 1, dropout=0.5, device='cpu'):\n",
    "        super(TriangularMotifsCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 16, kernel_size=3, stride=1, padding=1).to(device)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1).to(device)\n",
    "        self.fc1 = nn.Linear(32 * 64, 128, bias=True).to(device)  # Adjust the input size based on your data\n",
    "        self.fc2 = nn.Linear(128, output_dim, bias=True).to(device)  # Output size is 1  for regression\n",
    "        self.dropout = dropout\n",
    "        self.training = True\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        \n",
    "        print(\"x shape:\",x.shape)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        print(self.training)\n",
    "        x = self.fc2(x)\n",
    "         \n",
    "        out = x.reshape(-1)\n",
    "         \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.features.shape: torch.Size([1852, 4])\n",
      "input_dims (input dimension) -> self.features.shape[1] = 4\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "directory = \"models/\"\n",
    "fname = \"n1_e1234_egnnc_mlp_entropy_density_drop05_epoch100_hid16_out16_70_30_split_exp_saved_model.pth\"\n",
    "path = os.path.join(directory, fname)\n",
    "config = dict()\n",
    "config['hidden_dims'], config['out_dim'] = [16], 16\n",
    "config['device'] = 'cpu'\n",
    "config['dropout'] = 0.5\n",
    "config['task'] = 'link_prediction'\n",
    "\n",
    "input_dim, hidden_dim,  output_dim = datasets[0].get_dims()[0], config['hidden_dims'][0], config['out_dim']\n",
    "channel_dim = datasets[0].get_channel()\n",
    "\n",
    "model = EGNNC(input_dim, hidden_dim, output_dim,\n",
    "              channel_dim, 3, config['dropout'], config['device'])\n",
    "model.to(config['device'])\n",
    "\n",
    "\n",
    "mlp = models.MLPTwoLayers(input_dim=channel_dim*output_dim*4, hidden_dim=output_dim*4, output_dim=1, dropout=0.5)\n",
    "mlp.to(config[\"device\"])\n",
    "\n",
    "cnn_classifier = models.TriangularMotifsCNN(num_channels = 4)\n",
    "cnn_classifier.to(config[\"device\"])\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "criterion = utils.get_criterion(config['task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_TriangularMotifsCNN_input(features, edges, triangles, device=\"cpu\"):\n",
    "   \n",
    "    _u = torch.FloatTensor().to(device)\n",
    "    _v = torch.FloatTensor().to(device)\n",
    "    \n",
    "    _z = torch.FloatTensor().to(device)\n",
    "    _w = torch.FloatTensor().to(device)\n",
    "    \n",
    "    count = 0\n",
    "    for u, v in edges:\n",
    "        \n",
    "        t12 = triangles.get(frozenset((u,v)))\n",
    "        #print(\"Triangles: \", t12)\n",
    "        #print(\"Edge: \", (u,v))\n",
    "        if not t12 is None:\n",
    "            z, w = t12[0], t12[1]\n",
    "        else:\n",
    "            #print(\"------ Padding ------\")\n",
    "            print(\"Edge: \", (u,v))\n",
    "            count += 1\n",
    "            z, w = u, v\n",
    "\n",
    "        _u = torch.cat((_u, features[u].reshape(1, -1)), dim=0)\n",
    "        _v = torch.cat((_v, features[v].reshape(1, -1)), dim=0)\n",
    "        _z = torch.cat((_z, features[int(z)].reshape(1, -1)), dim=0)\n",
    "        _w = torch.cat((_w, features[int(w)].reshape(1, -1)), dim=0)\n",
    "        \n",
    "\n",
    "    if count> 0:\n",
    "        print(\"Padding count: \", count)\n",
    "    \n",
    "    input_data = torch.stack([_u,_v,_z,_w], dim=1)\n",
    "    input_data = input_data.permute(0,1,2)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 1\n",
      "    Graph 1 / 1: loss 0.3908\n",
      "    ROC-AUC score: 0.5170\n",
      "Epoch avg loss: 0.3908496451257281\n",
      "Epoch avg ROC_AUC score: 0.5169597886335174\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "config['lr'] = 1e-3\n",
    "config['weight_decay'] = 1e-4\n",
    "config['batch_size'] = 32\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                            weight_decay=config['weight_decay'])\n",
    "epochs = 1\n",
    "\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1500, gamma=0.8)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15, 20, 25], gamma=0.5) # Epoch decay\n",
    "model.train()\n",
    "cnn_classifier.train()\n",
    "print('--------------------------------')\n",
    "print('Training.')\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "    epoch_loss = 0.0\n",
    "    epoch_roc = 0.0\n",
    "    epoch_batches = 0\n",
    "    shuffle = list(range(len(loaders)))\n",
    "    random.shuffle(shuffle) # Shuffle order of graphs\n",
    "    for i in shuffle:\n",
    "        num_batches = int(ceil(len(datasets[i]) / config['batch_size']))\n",
    "        epoch_batches += num_batches\n",
    "        graph_roc = 0.0\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loaders[i]):\n",
    "            adj, features, edge_features, edges, labels, dist, triangles = batch\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "                    # EGNN\n",
    "            features, edge_features = features.to(device), edge_features.to(device)\n",
    "            out = model(features, edge_features)\n",
    "\n",
    "                    # CNN\n",
    "                    \n",
    "            cnn_input = create_TriangularMotifsCNN_input(out, edges, triangles, device)\n",
    "            #print(\"cnn_input.shape: \", cnn_input.shape)\n",
    "            cnn_out = cnn_classifier(cnn_input)\n",
    "            #print(\"cnn_out.shape: \", cnn_out.shape)\n",
    "            #print(\"labels.shape: \", labels.shape)         \n",
    "            scores = sigmoid(cnn_out)\n",
    "                        \n",
    "\n",
    "            loss = criterion(scores, labels.float()) # Loss function for BCE loss\n",
    "            #loss = utils.get_focal_loss_criterion(scores, labels.float())  # Loss function for Focal Loss \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "                epoch_loss += loss.item()\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().cpu().numpy(), scores.detach().cpu().numpy())\n",
    "                    epoch_roc += area\n",
    "                    graph_roc += area\n",
    "        running_loss /= num_batches\n",
    "        print('    Graph {} / {}: loss {:.4f}'.format(\n",
    "                i+1, len(datasets), running_loss))\n",
    "        print('    ROC-AUC score: {:.4f}'.format(graph_roc/num_batches))\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\"Epoch avg loss: {}\".format(epoch_loss / epoch_batches))\n",
    "    print(\"Epoch avg ROC_AUC score: {}\".format(epoch_roc / epoch_batches))\n",
    "\n",
    "print('Finished training.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0827, 0.0236, 0.0234, 0.0119, 0.0327, 0.0778, 0.0811, 0.0703, 0.0160,\n",
       "         0.2096], grad_fn=<SigmoidBackward0>),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1365, -0.4436, -0.9728,  ...,  1.6593, -2.1159,  2.0860],\n",
       "         [ 1.8839, -1.4095, -1.7701,  ...,  1.6381, -1.9976,  1.9533],\n",
       "         [ 0.8478, -0.4772, -0.8002,  ...,  1.4776, -2.0392,  2.2021],\n",
       "         ...,\n",
       "         [-0.1480,  0.0464,  0.0748,  ...,  0.0928, -0.0188,  0.3521],\n",
       "         [ 1.0319, -1.1962, -0.9603,  ...,  0.3912,  0.2173,  0.2191],\n",
       "         [-0.8643,  0.7457,  0.7227,  ..., -0.9609,  0.0982,  0.0715]],\n",
       "        grad_fn=<DivBackward0>),\n",
       " tensor([[ -8.0259,   1.1088,   8.6465,  ...,  -2.8202,   6.0319,  -6.4001],\n",
       "         [  2.2959,  -4.9667,  -4.3359,  ...,  -2.8708,   6.4991,  -7.0512],\n",
       "         [-12.0124,   0.8972,  11.4571,  ...,  -3.2548,   6.3346,  -5.8304],\n",
       "         ...,\n",
       "         [-25.7646,   4.1905,  25.7066,  ...,  -6.5681,  14.3165, -14.9083],\n",
       "         [ -9.4710,  -3.6248,   8.8504,  ...,  -5.8540,  15.2491, -15.5608],\n",
       "         [-35.6560,   8.5886,  36.2573,  ...,  -9.0891,  14.7786, -16.2850]],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_norm = (out - out.mean(dim=0)) / out.std(dim=0)\n",
    "out_norm, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_input.shape:  torch.Size([10, 4, 64])\n",
      "x shape: torch.Size([10, 2048])\n",
      "torch.Size([10, 128])\n",
      "torch.Size([10, 1])\n",
      "out: torch.Size([10])\n",
      "cnn_out.shape:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "cnn_input = create_TriangularMotifsCNN_input(out, edges, triangles, device)\n",
    "print(\"cnn_input.shape: \", cnn_input.shape)\n",
    "cnn_out = cnn_classifier(cnn_input)\n",
    "print(\"cnn_out.shape: \", cnn_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv = torch.ones(32, 64)\n",
    "_z = torch.zeros(32, 64)\n",
    "_w = torch.ones(32, 64)\n",
    "\n",
    "\n",
    "input_data = torch.stack([uv, _z], dim=1)\n",
    "#input_data = input_data.view(-1, 2, 16, 16)\n",
    "input_data = input_data.permute(0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_repr1 = torch.randn(32, 192)\n",
    "node_repr2 = torch.randn(32, 192)\n",
    "triangle_repr1 = torch.randn(32, 192)\n",
    "triangle_repr2 = torch.randn(32, 192)\n",
    "\n",
    "# Concatenate the node representations and reshape into a 4-channel input for the CNN\n",
    "input_data = torch.stack([node_repr1, node_repr2, triangle_repr1, triangle_repr2], dim=1)\n",
    "input_data = input_data.view(-1, 4*3, 8, 8)\n",
    "\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.Tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 2, 2, 1]\n",
    "])\n",
    "\n",
    "weight0 = torch.Tensor([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 2, 2, 2, 2],\n",
    "    [5, 4, 3, 2, 1]\n",
    "])\n",
    "\n",
    "weight00 = torch.randn(4, 3)\n",
    "\n",
    "weight1 = torch.Tensor([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [2, 2, 2, 2, 2],\n",
    "    [0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "edge_features = torch.Tensor([\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [3, 2, 1],\n",
    "        [2, 2, 2]\n",
    "    ],\n",
    "    [\n",
    "        [1, 1, 1],\n",
    "        [2, 2, 2],\n",
    "        [3, 3, 3]\n",
    "    ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.matmul(features, weight0)\n",
    "x1 = torch.matmul(features, weight1)\n",
    "x2 = torch.matmul(edge_features, x0)\n",
    "output = torch.cat([xi for xi in x2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x00 = torch.matmul(features, weight00)\n",
    "x10 = torch.matmul(features, weight00)\n",
    "x20 = torch.matmul(edge_features, x00)\n",
    "output0 = torch.cat([xi for xi in x20], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 83.,  84.,  85.,  86.,  87.,  50.,  49.,  48.,  47.,  46.],\n",
       "        [117., 112., 107., 102.,  97., 100.,  98.,  96.,  94.,  92.],\n",
       "        [100.,  98.,  96.,  94.,  92., 150., 147., 144., 141., 138.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29., 27., 25., 23., 21.],\n",
       "        [ 9.,  9.,  9.,  9.,  9.],\n",
       "        [12., 13., 14., 15., 16.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 7., 7., 7.],\n",
       "        [3., 3., 3., 3., 3.],\n",
       "        [5., 5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 83.,  84.,  85.,  86.,  87.],\n",
       "         [117., 112., 107., 102.,  97.],\n",
       "         [100.,  98.,  96.,  94.,  92.]],\n",
       "\n",
       "        [[ 50.,  49.,  48.,  47.,  46.],\n",
       "         [100.,  98.,  96.,  94.,  92.],\n",
       "         [150., 147., 144., 141., 138.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 90.,  91.,  92.,  93.,  94.],\n",
       "         [120., 115., 110., 105., 100.],\n",
       "         [105., 103., 101.,  99.,  97.]],\n",
       "\n",
       "        [[ 57.,  56.,  55.,  54.,  53.],\n",
       "         [103., 101.,  99.,  97.,  95.],\n",
       "         [155., 152., 149., 146., 143.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 + x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = utils.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([\n",
    "    [1, 2, 3],\n",
    "    [2, 3, 4],\n",
    "    [3, 4, 5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [2., 3., 4.],\n",
       "         [3., 4., 5.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccaac013b6b6e9b32d0a0d6e96288a02ed656e9518d9a1239996f4b4a38ebffb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DigitalPathology')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
